{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bulgarian-monaco",
   "metadata": {},
   "source": [
    "# Lab №2 made by Pinaev Zakhar J41322c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "better-encyclopedia",
   "metadata": {},
   "source": [
    "## Setting workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-magic",
   "metadata": {},
   "source": [
    "#### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "accompanied-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql.functions import pandas_udf, udf, size, length, when, col, array_contains, row_number\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType, IntegerType, ArrayType, StringType, StructType, StructField\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "\n",
    "import pyarrow as pa\n",
    "import emoji\n",
    "import re\n",
    "import socket\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "employed-egypt",
   "metadata": {},
   "source": [
    "#### Getting LOCAL_IP of current port to make executors able to find us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "about-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOCAL_IP = socket.gethostbyname(socket.gethostname())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "known-screw",
   "metadata": {},
   "source": [
    "#### Configuring Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "equipped-property",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession\n",
    "    .builder\n",
    "    .master('k8s://https://10.32.7.103:6443')\n",
    "    .config(\"spark.driver.host\", LOCAL_IP)\n",
    "    .config(\"spark.driver.bindAddress\", \"0.0.0.0\")\n",
    "    .config('spark.executor.instences', '2')\n",
    "    .config('spark.executor.cores', '2')\n",
    "    .config('spark.cores.max', '4')\n",
    "    .config('spark.executor.memory', '4g')\n",
    "    .config('spark.sql.execution.arrow.enabled', 'true')\n",
    "    .config('spark.kubernetes.namespace', 'zpinaev-244202')\n",
    "    .config('spark.kubernetes.container.image', 'node03.st:5000/spark-executor:zpinaev-244202')\n",
    "    .config(\"spark.kubernetes.container.image.pullPolicy\", \"Always\")\n",
    "    .config('spark.kubernetes.executor.deleteOnTermination', 'false')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-dining",
   "metadata": {},
   "source": [
    "#### Reading all data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "disturbed-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = spark.read.json(\"hdfs:///shared/bigdata20/posts_api.json\")\n",
    "\n",
    "posts_likes_df = spark.read.parquet(\"hdfs:///shared/bigdata20/posts_likes.parquet\")\n",
    "followers_df = spark.read.parquet(\"hdfs:///shared/bigdata20/followers.parquet\")\n",
    "followers_posts_df = spark.read.json(\"hdfs:///shared/bigdata20/followers_posts_api_final.json\")\n",
    "followers_posts_likes_df = spark.read.parquet(\"hdfs:///shared/bigdata20/followers_posts_likes.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-individual",
   "metadata": {},
   "source": [
    "#### Caching all input data de bene esse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "id": "sufficient-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_df = posts_df.cache()\n",
    "posts_likes_df = posts_likes_df.cache()\n",
    "followers_df = followers_df.cache()\n",
    "followers_posts_df = followers_posts_df.cache()\n",
    "followers_posts_likes_df = followers_posts_likes_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unauthorized-tribune",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "### Find the top 20 posts in the group"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sweet-shirt",
   "metadata": {},
   "source": [
    "#### Selecting subset of needed info for task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "streaming-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1_df = posts_df.select(\"id\", \"text\",\n",
    "                            col(\"likes.count\").name(\"likecount\"),\n",
    "                            col(\"reposts.count\").name(\"repcount\"),\n",
    "                            col(\"comments.count\").name(\"comcount\")).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "historical-aruba",
   "metadata": {},
   "source": [
    "### (a) by likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "binary-ticket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------+--------+--------+\n",
      "|   id|                text|likecount|repcount|comcount|\n",
      "+-----+--------------------+---------+--------+--------+\n",
      "|32022|Стесняешься петь ...|     1637|     210|      27|\n",
      "|35068|У нас для вас две...|     1629|     101|       4|\n",
      "|17492|Настали снежные х...|     1516|     334|      42|\n",
      "|18526|[Пригласи друзей ...|     1026|      31|       9|\n",
      "|19552|Ура! Нас 20 000! ...|      955|     246|       3|\n",
      "|41468|Добро пожаловать ...|      952|      85|      33|\n",
      "|19419|[Университет ИТМО...|      868|     126|       7|\n",
      "|29046|Я ПОСТУПИЛ В УНИВ...|      824|      87|      20|\n",
      "|32546|WE ARE THE CHAMPI...|      786|      68|      20|\n",
      "|24085|Студенты, сегодня...|      765|      57|     850|\n",
      "|40180|Ура! Кубок ICPC с...|      759|       2|      10|\n",
      "|33658|ITMO.GO! Я поступ...|      708|      60|      11|\n",
      "|13532|Команда студентов...|      633|     110|      15|\n",
      "|40842|Хочешь поздравить...|      631|      17|       2|\n",
      "|35117|К концу года мы д...|      588|      34|       1|\n",
      "|17014|#ExamsAreComing #...|      581|     105|      10|\n",
      "|19583|[Я участвую в вел...|      553|      68|       3|\n",
      "|19809|[Билет на GEEK PI...|      552|      84|      11|\n",
      "|27455|А вы хотите на Ge...|      550|      55|      15|\n",
      "|11999|Начало конкурса М...|      549|      85|      17|\n",
      "+-----+--------------------+---------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_1_df.orderBy(\"likecount\", ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "quiet-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1_df.orderBy(\"likecount\", ascending=False).write.parquet(\"hdfs:///tmp/zpinaev-244202/lab2_results_1a.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-mechanism",
   "metadata": {},
   "source": [
    "### (b) by comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "personalized-drove",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------+--------+--------+\n",
      "|   id|                text|likecount|repcount|comcount|\n",
      "+-----+--------------------+---------+--------+--------+\n",
      "|24085|Студенты, сегодня...|      765|      57|     850|\n",
      "|22540|Друзья, а давайте...|      212|      12|     250|\n",
      "|27722|Upd: розыгрыш зав...|       23|       0|     192|\n",
      "| 8285|Все знают, что в ...|        5|       1|     148|\n",
      "|26860|18 мая состоится ...|      197|      23|     113|\n",
      "|13571|15 российских вуз...|      114|      35|     107|\n",
      "|39294|Информация по ава...|      231|      19|     104|\n",
      "|36680|ОФИЦИАЛЬНО: СЕССИ...|       43|       2|      96|\n",
      "|26006|Дорогие абитуриен...|       12|       1|      92|\n",
      "|41739|ДОБРО ПОЖАЛОВАТЬ ...|       71|       0|      92|\n",
      "|12426|Уважаемые студент...|        9|       6|      91|\n",
      "|21499|Внимание! Розыгры...|      101|      11|      88|\n",
      "|39163|Science Valentine...|       35|       3|      83|\n",
      "|39407|Информация по ава...|      152|      12|      83|\n",
      "|11267|                    |        4|       0|      81|\n",
      "|31548|Роботы пишут стих...|       12|       3|      80|\n",
      "|11158|Опубликованы прик...|       23|       4|      70|\n",
      "|39082|Пришла пора узнат...|       41|       3|      67|\n",
      "|14602|В рамках реализац...|       37|      18|      61|\n",
      "|12687|Придумай название...|       16|      16|      61|\n",
      "+-----+--------------------+---------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_1_df.orderBy(\"comcount\", ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "numerous-charger",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1_df.orderBy(\"comcount\", ascending=False).write.parquet(\"hdfs:///tmp/zpinaev-244202/lab2_results_1b.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-tsunami",
   "metadata": {},
   "source": [
    "### (c) by reposts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "disturbed-generic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+---------+--------+--------+\n",
      "|   id|                text|likecount|repcount|comcount|\n",
      "+-----+--------------------+---------+--------+--------+\n",
      "|17492|Настали снежные х...|     1516|     334|      42|\n",
      "|19552|Ура! Нас 20 000! ...|      955|     246|       3|\n",
      "|32022|Стесняешься петь ...|     1637|     210|      27|\n",
      "|11842|8 октября пропал ...|      197|     129|       7|\n",
      "|19419|[Университет ИТМО...|      868|     126|       7|\n",
      "|13532|Команда студентов...|      633|     110|      15|\n",
      "|17014|#ExamsAreComing #...|      581|     105|      10|\n",
      "|35068|У нас для вас две...|     1629|     101|       4|\n",
      "|41266|В преддверии выпу...|      433|      92|       7|\n",
      "|12593|Подарок всем студ...|      483|      90|      48|\n",
      "|29046|Я ПОСТУПИЛ В УНИВ...|      824|      87|      20|\n",
      "|11999|Начало конкурса М...|      549|      85|      17|\n",
      "|41468|Добро пожаловать ...|      952|      85|      33|\n",
      "|19809|[Билет на GEEK PI...|      552|      84|      11|\n",
      "|17167|🎄Выходные дни в ...|       92|      81|       0|\n",
      "|10833|МЫ СНОВА АБСОЛЮТН...|      491|      78|      14|\n",
      "|18543|[TechTrends Expo ...|      227|      77|      19|\n",
      "|16596|[Выходные дни в н...|       97|      76|       4|\n",
      "|18156|[Выиграй билеты н...|      160|      74|       4|\n",
      "|37262|Лето. Жара. Петер...|      369|      71|       3|\n",
      "+-----+--------------------+---------+--------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "task_1_df.orderBy(\"repcount\", ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "informal-camera",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_1_df.orderBy(\"repcount\", ascending=False).write.parquet(\"hdfs:///tmp/zpinaev-244202/lab2_results_1c.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-shower",
   "metadata": {},
   "source": [
    "#### drop cache of task 1 df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "featured-cherry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, text: string, likecount: bigint, repcount: bigint, comcount: bigint]"
      ]
     },
     "execution_count": 623,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_1_df.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trained-incidence",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "### Find the top 20 users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-meditation",
   "metadata": {},
   "source": [
    "### (a) by likes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promotional-relaxation",
   "metadata": {},
   "source": [
    "#### We get df with likes for the public posts of the followers and count number of likes from each user - than sort by likes num and show top 20 of users by likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "isolated-company",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+\n",
      "|  likerId|likes_count|\n",
      "+---------+-----------+\n",
      "|194073434|       8104|\n",
      "|150371150|       5332|\n",
      "|271081114|       5261|\n",
      "|  6524088|       4946|\n",
      "|189597336|       3711|\n",
      "|142999083|       3394|\n",
      "|215686327|       3217|\n",
      "|514404131|       2747|\n",
      "|  2818498|       2350|\n",
      "|419925361|       2212|\n",
      "|493380857|       2162|\n",
      "|424434709|       2122|\n",
      "| 95783577|       1985|\n",
      "| 94697255|       1975|\n",
      "|  4448812|       1777|\n",
      "|330771656|       1763|\n",
      "|228571738|       1720|\n",
      "|325927416|       1661|\n",
      "|347711731|       1645|\n",
      "|501177379|       1641|\n",
      "+---------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "followers_posts_likes_df\\\n",
    "                        .groupby(\"likerId\")\\\n",
    "                        .agg(F.count(\"likerId\").name(\"likes_count\"))\\\n",
    "                        .orderBy(\"likes_count\", ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "indian-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_posts_likes_df\\\n",
    "                        .groupby(\"likerId\")\\\n",
    "                        .agg(F.count(\"likerId\").name(\"likes_count\"))\\\n",
    "                        .orderBy(\"likes_count\", ascending=False).write.parquet(\"hdfs:///tmp/zpinaev-244202/lab2_results_2a.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sublime-approval",
   "metadata": {},
   "source": [
    "### (b) by reposts they have made"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artistic-moore",
   "metadata": {},
   "source": [
    "#### We check if field 'copy_history' is not null, to know, if post was reposted from somewhere. Then select id's of users, who reposted post and grouping by those id's counting, how many times each user reposted something."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "affecting-following",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "|  from_id|rep_count|\n",
      "+---------+---------+\n",
      "|  2547211|    37742|\n",
      "|357231922|    23349|\n",
      "|168543860|    18429|\n",
      "| 25646344|    11122|\n",
      "|176861294|     9022|\n",
      "|524656784|     7242|\n",
      "|    29840|     7164|\n",
      "|143207077|     7161|\n",
      "|141687240|     6804|\n",
      "|459339006|     6741|\n",
      "|514384760|     6570|\n",
      "|483715951|     6052|\n",
      "|445159771|     5808|\n",
      "|451211328|     5646|\n",
      "|426396104|     5533|\n",
      "|  8325325|     5532|\n",
      "|452280411|     5458|\n",
      "|464220898|     5318|\n",
      "|440454268|     5304|\n",
      "|461319529|     5240|\n",
      "+---------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "followers_posts_df\\\n",
    "                .where(col(\"copy_history\").isNotNull())\\\n",
    "                .select(\"from_id\").groupby(\"from_id\")\\\n",
    "                .agg(F.count(\"from_id\").name(\"rep_count\"))\\\n",
    "                .orderBy(\"rep_count\", ascending=False).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "pacific-magic",
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_posts_df\\\n",
    "                .where(col(\"copy_history\").isNotNull())\\\n",
    "                .select(\"from_id\").groupby(\"from_id\")\\\n",
    "                .agg(F.count(\"from_id\").name(\"rep_count\"))\\\n",
    "                .orderBy(\"rep_count\", ascending=False).write.parquet(\"hdfs:///tmp/zpinaev-244202/lab2_results_2b.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-representation",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "### Get reposts of the original posts of the itmo group from user posts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-bowling",
   "metadata": {},
   "source": [
    "#### First we look for reposts from itmo group (owner_id=-94) among all reposts of users. Then we group by post id ('copy_history.id') and collect user post ids ('id') to a list. Then we searh for group posts that were reposted and get their group id's. Finally we join those two df's by 'copy_history.id' and 'id' respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "physical-gamma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------+\n",
      "|          group_text|group_post_id|            usr_text|  usrs_post_id|\n",
      "+--------------------+-------------+--------------------+--------------+\n",
      "|Университет ИТМО ...|        41402|Университет ИТМО ...|[212, 55, 405]|\n",
      "|Так-так, где же в...|        41282|Так-так, где же в...|       [10669]|\n",
      "|Первые по Петербу...|        38767|Первые по Петербу...|    [778, 364]|\n",
      "|Лучшее чтение на ...|        42714|Лучшее чтение на ...|       [12501]|\n",
      "|Стартовала регист...|        38877|Стартовала регист...|        [9722]|\n",
      "+--------------------+-------------+--------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "users_posts_id_df = followers_posts_df\\\n",
    "                    .where(col(\"copy_history\").isNotNull())\\\n",
    "                    .where(col(\"copy_history.owner_id\").getItem(0) == -94)\\\n",
    "                    .select(col(\"copy_history.id\")[0].name(\"id\"), \n",
    "                            col(\"copy_history.text\")[0].name(\"usr_text\"), \n",
    "                            col(\"id\").name(\"usr_post_id\"))\\\n",
    "                    .groupby(\"id\", \"usr_text\")\\\n",
    "                    .agg(F.collect_list(col(\"usr_post_id\")).name(\"usrs_post_id\"))\\\n",
    "                    .cache()\n",
    "\n",
    "\n",
    "group_posts_id = posts_df\\\n",
    "                    .where(col(\"copy_history\").isNotNull())\\\n",
    "                    .select(col(\"text\").name(\"group_text\"), col(\"id\").name(\"group_post_id\"))\\\n",
    "                    .cache()\n",
    "\n",
    "\n",
    "group_posts_id.join(users_posts_id_df, \n",
    "                    on=[group_posts_id.group_post_id == users_posts_id_df.id])\\\n",
    "                    .drop(\"id\")\\\n",
    "                    .show(5)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "latin-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_posts_id.join(users_posts_id_df, \n",
    "                    on=[group_posts_id.group_post_id == users_posts_id_df.id])\\\n",
    "                    .drop(\"id\").write.parquet(\"hdfs:///tmp/zpinaev-244202/lab2_results_3.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "pursuant-florist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[group_text: string, group_post_id: bigint]"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_posts_id_df.unpersist()\n",
    "group_posts_id.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-substitute",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "### Emoticon task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "harmful-activity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|                text|\n",
      "+--------------------+\n",
      "|Я люблю Вас. Я вч...|\n",
      "|call me by your n...|\n",
      "|                  🦋|\n",
      "|         Браво,Юра !|\n",
      "|                  🕊|\n",
      "|Самый неприятный ...|\n",
      "|                  🔅|\n",
      "|Пекло.Пушка.Вышка...|\n",
      "|Тот неловкий моме...|\n",
      "|Белые ночи + жарк...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# selecting only text column from followers posts\n",
    "folowers_posts_text = followers_posts_df\\\n",
    "                        .where(col(\"text\") != \"\")\\\n",
    "                        .select(col(\"text\")).cache()\n",
    "folowers_posts_text.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "brutal-essay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189848"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of posts\n",
    "folowers_posts_text.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "under-curtis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+\n",
      "|Emoji|Sentiment|\n",
      "+-----+---------+\n",
      "|   😂| positive|\n",
      "|    ❤| positive|\n",
      "|    ♥| positive|\n",
      "|   😍| positive|\n",
      "|   😭| negative|\n",
      "|   😘| positive|\n",
      "|   😊| positive|\n",
      "|   👌| positive|\n",
      "|   💕| positive|\n",
      "|   👏| positive|\n",
      "+-----+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# creating spark DF with emoji/sentiment info from external file\n",
    "emoji_pdf = pd.read_excel(\"Emoji_Sentiment_Data2.xls\")\n",
    "\n",
    "emoji_sent_df = spark.createDataFrame(emoji_pdf).select(\"Emoji\", \"Sentiment\")\n",
    "\n",
    "emoji_sent_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "domestic-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_emojis(s):\n",
    "    if s is None:\n",
    "        return ''\n",
    "    return ''.join(c for c in s if c in emoji.UNICODE_EMOJI['en'])\n",
    "\n",
    "# udf to extract emojis from column texts\n",
    "search_all_emojis = udf(extract_emojis, returnType=StringType())\n",
    "\n",
    "# dataframe of one column containing emojis found in each row text\n",
    "emojis_df = folowers_posts_text.withColumn(\"emoji_in_post\", search_all_emojis(col(\"text\")))\n",
    "\n",
    "# list of found emojis where every element is a string of emojis from some post\n",
    "listEmoji = [row[\"emoji_in_post\"] for row in emojis_df.where(col(\"emoji_in_post\")!='').collect()]\n",
    "\n",
    "## dict with emojis and their sentiment\n",
    "emojisDict = { row[\"Emoji\"] : row[\"Sentiment\"] for row in emoji_sent_df.collect() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "private-coast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with separate emojis\n",
    "sepEmoji_df = emoji_sent_df.select(\"emoji\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "prerequisite-makeup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcasting dict with emojis and list of found emoijs from posts\n",
    "emojisDictBcs = spark.sparkContext.broadcast(emojisDict)\n",
    "listEmojiBcs = spark.sparkContext.broadcast(listEmoji)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "liberal-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metricCalc(cur_emoji):\n",
    "    emojiDict = emojisDictBcs.value\n",
    "    emojisPostsList = listEmojiBcs.value\n",
    "    \n",
    "    overallCount = sum(strings.count(cur_emoji) for strings in emojisPostsList)\n",
    "    \n",
    "    postsNum = sum(1 for s in emojisPostsList if cur_emoji in s)\n",
    "    if postsNum == 0:\n",
    "        postsNum = 1\n",
    "    \n",
    "    frequency = postsNum / 189848\n",
    "    \n",
    "    avCountPost = overallCount / postsNum\n",
    "    overFreqDiff = overallCount - frequency\n",
    "    sentiment = emojiDict[cur_emoji]\n",
    "    return Row(\"sentiment\", \"overallCount\", \"frequency\",\n",
    "               \"avCountPost\", \"overallFreqDiff\")(sentiment, overallCount,\n",
    "                                                 frequency, avCountPost,\n",
    "                                                 overFreqDiff)\n",
    "    \n",
    "outputSchema = StructType([\n",
    "    StructField(\"sentiment\", StringType(), False),\n",
    "    StructField(\"overallCount\", IntegerType(), False),\n",
    "    StructField(\"frequency\", FloatType(), False),\n",
    "    StructField(\"avCountPost\", FloatType(), False),\n",
    "    StructField(\"overallFreqDiff\", FloatType(), False),\n",
    "])\n",
    "\n",
    "metricCalcUdf = udf(metricCalc, outputSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "duplicate-barcelona",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultEmoji_df = sepEmoji_df.withColumn(\"output\", metricCalcUdf(sepEmoji_df['emoji']))\\\n",
    "                            .select(*(sepEmoji_df.columns), \"output.*\")\\\n",
    "                            .where(col(\"overallCount\") != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "parliamentary-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultEmoji_df.write.parquet(\"hdfs:///tmp/zpinaev-244202/lab2_results.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-advertising",
   "metadata": {},
   "source": [
    "### Additionally, for each sentiment print:\n",
    "### 1) top 10 most popular emoticons by their overall count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "french-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(\"sentiment\").orderBy(col(\"overallCount\").desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-execution",
   "metadata": {},
   "source": [
    "#### negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "alone-brooks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|emoji|sentiment|overallCount|   frequency|avCountPost|overallFreqDiff|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|   📌| negative|        1427|0.0039768657|  1.8900663|       1426.996|\n",
      "|   😭| negative|         483| 0.001232565|  2.0641026|      482.99878|\n",
      "|    ⏳| negative|         412|0.0021332856|  1.0172839|      411.99786|\n",
      "|   🚩| negative|         271|5.6887616E-4|  2.5092592|      270.99942|\n",
      "|   😔| negative|         251|0.0011008807|   1.200957|       250.9989|\n",
      "|   💔| negative|         251|0.0010166027|  1.3005182|      250.99898|\n",
      "|    ➖| negative|         249|1.3695167E-4|   9.576923|      248.99986|\n",
      "|   😨| negative|         241|0.0010218702|  1.2422681|      240.99898|\n",
      "|   👎| negative|         231|0.0011219502|   1.084507|      230.99887|\n",
      "|   😤| negative|         206| 9.797312E-4|  1.1075269|      205.99902|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultEmoji_df\\\n",
    "            .withColumn(\"emojiTop\",row_number().over(windowSpec))\\\n",
    "            .where(col(\"emojiTop\") < 11)\\\n",
    "            .where(col(\"sentiment\")==\"negative\")\\\n",
    "            .drop(\"emojiTop\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charged-clark",
   "metadata": {},
   "source": [
    "#### neutral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "spoken-administration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|emoji|sentiment|overallCount|   frequency|avCountPost|overallFreqDiff|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|   🔥|  neutral|       11774| 0.022423202|  2.7657976|      11773.978|\n",
      "|    ®|  neutral|        9144|0.0022860393|  21.069124|       9143.998|\n",
      "|   💥|  neutral|        4669|  0.00968143|  2.5402613|        4668.99|\n",
      "|    ❗|  neutral|        3563|0.0062260334|  3.0143824|      3562.9937|\n",
      "|    ✨|  neutral|        2833|0.0060838144|  2.4528139|       2832.994|\n",
      "|   👉|  neutral|        1637|  0.00420863|   2.048811|      1636.9958|\n",
      "|   💰|  neutral|        1365| 0.004935527|   1.456777|      1364.9951|\n",
      "|    ♀|  neutral|        1280|0.0046142177|  1.4611872|      1279.9954|\n",
      "|    ©|  neutral|        1150|0.0030866798|  1.9624573|       1149.997|\n",
      "|   😏|  neutral|        1132| 0.004292908|   1.388957|      1131.9957|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultEmoji_df\\\n",
    "            .withColumn(\"emojiTop\",row_number().over(windowSpec))\\\n",
    "            .where(col(\"emojiTop\") < 11)\\\n",
    "            .where(col(\"sentiment\")==\"neutral\")\\\n",
    "            .drop(\"emojiTop\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-front",
   "metadata": {},
   "source": [
    "#### positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "specialized-melbourne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|emoji|sentiment|overallCount|   frequency|avCountPost|overallFreqDiff|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|    ❤| positive|       15253| 0.033721715|  2.3825366|      15252.966|\n",
      "|   👍| positive|        7773| 0.018040748|   2.269489|       7772.982|\n",
      "|   😂| positive|        5554| 0.012262441|  2.3857388|       5553.988|\n",
      "|   🌺| positive|        5470|0.0061575575|   4.679213|      5469.9937|\n",
      "|   😍| positive|        4583|0.0144115295|  1.6750731|      4582.9854|\n",
      "|   🔻| positive|        4115| 9.323248E-4|  23.248587|       4114.999|\n",
      "|   🎀| positive|        3788|0.0032552357|    6.12945|      3787.9968|\n",
      "|   😉| positive|        3687| 0.014764443|  1.3153764|      3686.9854|\n",
      "|    ☀| positive|        3243|0.0069634654|  2.4531014|       3242.993|\n",
      "|    ✅| positive|        2985| 0.005409591|   2.906524|      2984.9946|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultEmoji_df\\\n",
    "            .withColumn(\"emojiTop\",row_number().over(windowSpec))\\\n",
    "            .where(col(\"emojiTop\") < 11)\\\n",
    "            .where(col(\"sentiment\")==\"positive\")\\\n",
    "            .drop(\"emojiTop\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detected-thought",
   "metadata": {},
   "source": [
    "### 2) top 5 emoticons which have the greatest difference between their overall count and frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "proved-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(\"sentiment\").orderBy(col(\"overallFreqDiff\").desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-prescription",
   "metadata": {},
   "source": [
    "#### negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "id": "popular-creativity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|emoji|sentiment|overallCount|   frequency|avCountPost|overallFreqDiff|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|   📌| negative|        1427|0.0039768657|  1.8900663|       1426.996|\n",
      "|   😭| negative|         483| 0.001232565|  2.0641026|      482.99878|\n",
      "|    ⏳| negative|         412|0.0021332856|  1.0172839|      411.99786|\n",
      "|   🚩| negative|         271|5.6887616E-4|  2.5092592|      270.99942|\n",
      "|   💔| negative|         251|0.0010166027|  1.3005182|      250.99898|\n",
      "|   😔| negative|         251|0.0011008807|   1.200957|       250.9989|\n",
      "|    ➖| negative|         249|1.3695167E-4|   9.576923|      248.99986|\n",
      "|   😨| negative|         241|0.0010218702|  1.2422681|      240.99898|\n",
      "|   👎| negative|         231|0.0011219502|   1.084507|      230.99887|\n",
      "|   😤| negative|         206| 9.797312E-4|  1.1075269|      205.99902|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultEmoji_df\\\n",
    "            .withColumn(\"emojiTop\",row_number().over(windowSpec))\\\n",
    "            .where(col(\"emojiTop\") < 11)\\\n",
    "            .where(col(\"sentiment\")==\"negative\")\\\n",
    "            .drop(\"emojiTop\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-pride",
   "metadata": {},
   "source": [
    "#### neutral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "id": "outside-router",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|emoji|sentiment|overallCount|   frequency|avCountPost|overallFreqDiff|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|   🔥|  neutral|       11774| 0.022423202|  2.7657976|      11773.978|\n",
      "|    ®|  neutral|        9144|0.0022860393|  21.069124|       9143.998|\n",
      "|   💥|  neutral|        4669|  0.00968143|  2.5402613|        4668.99|\n",
      "|    ❗|  neutral|        3563|0.0062260334|  3.0143824|      3562.9937|\n",
      "|    ✨|  neutral|        2833|0.0060838144|  2.4528139|       2832.994|\n",
      "|   👉|  neutral|        1637|  0.00420863|   2.048811|      1636.9958|\n",
      "|   💰|  neutral|        1365| 0.004935527|   1.456777|      1364.9951|\n",
      "|    ♀|  neutral|        1280|0.0046142177|  1.4611872|      1279.9954|\n",
      "|    ©|  neutral|        1150|0.0030866798|  1.9624573|       1149.997|\n",
      "|   😏|  neutral|        1132| 0.004292908|   1.388957|      1131.9957|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultEmoji_df\\\n",
    "            .withColumn(\"emojiTop\",row_number().over(windowSpec))\\\n",
    "            .where(col(\"emojiTop\") < 11)\\\n",
    "            .where(col(\"sentiment\")==\"neutral\")\\\n",
    "            .drop(\"emojiTop\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-fabric",
   "metadata": {},
   "source": [
    "#### positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "guided-rochester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|emoji|sentiment|overallCount|   frequency|avCountPost|overallFreqDiff|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|    ❤| positive|       15253| 0.033721715|  2.3825366|      15252.966|\n",
      "|   👍| positive|        7773| 0.018040748|   2.269489|       7772.982|\n",
      "|   😂| positive|        5554| 0.012262441|  2.3857388|       5553.988|\n",
      "|   🌺| positive|        5470|0.0061575575|   4.679213|      5469.9937|\n",
      "|   😍| positive|        4583|0.0144115295|  1.6750731|      4582.9854|\n",
      "|   🔻| positive|        4115| 9.323248E-4|  23.248587|       4114.999|\n",
      "|   🎀| positive|        3788|0.0032552357|    6.12945|      3787.9968|\n",
      "|   😉| positive|        3687| 0.014764443|  1.3153764|      3686.9854|\n",
      "|    ☀| positive|        3243|0.0069634654|  2.4531014|       3242.993|\n",
      "|    ✅| positive|        2985| 0.005409591|   2.906524|      2984.9946|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultEmoji_df\\\n",
    "            .withColumn(\"emojiTop\",row_number().over(windowSpec))\\\n",
    "            .where(col(\"emojiTop\") < 11)\\\n",
    "            .where(col(\"sentiment\")==\"positive\")\\\n",
    "            .drop(\"emojiTop\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "starting-durham",
   "metadata": {},
   "source": [
    "### 3) top 5 emoticons with average count per post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "absent-seeking",
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSpec = Window.partitionBy(\"sentiment\").orderBy(col(\"avCountPost\").desc())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legal-vintage",
   "metadata": {},
   "source": [
    "#### negative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "id": "grateful-healing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|emoji|sentiment|overallCount|   frequency|avCountPost|overallFreqDiff|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|    ➖| negative|         249|1.3695167E-4|   9.576923|      248.99986|\n",
      "|    ✝| negative|          20|1.5802116E-5|  6.6666665|      19.999985|\n",
      "|    ➰| negative|          14|1.5802116E-5|  4.6666665|      13.999984|\n",
      "|   🚩| negative|         271|5.6887616E-4|  2.5092592|      270.99942|\n",
      "|   😭| negative|         483| 0.001232565|  2.0641026|      482.99878|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultEmoji_df\\\n",
    "            .withColumn(\"emojiTop\",row_number().over(windowSpec))\\\n",
    "            .where(col(\"emojiTop\") < 6)\\\n",
    "            .where(col(\"sentiment\")==\"negative\")\\\n",
    "            .drop(\"emojiTop\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-valve",
   "metadata": {},
   "source": [
    "#### neutral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "regular-cooperation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|emoji|sentiment|overallCount|   frequency|avCountPost|overallFreqDiff|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "|    ®|  neutral|        9144|0.0022860393|  21.069124|       9143.998|\n",
      "|   🔣|  neutral|          10|5.2673718E-6|       10.0|       9.999994|\n",
      "|   🔹|  neutral|         943| 9.007206E-4|    5.51462|       942.9991|\n",
      "|    ▪|  neutral|         258|2.6863595E-4|  5.0588236|      257.99973|\n",
      "|   🔘|  neutral|          15|1.5802116E-5|        5.0|      14.999984|\n",
      "+-----+---------+------------+------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultEmoji_df\\\n",
    "            .withColumn(\"emojiTop\",row_number().over(windowSpec))\\\n",
    "            .where(col(\"emojiTop\") < 6)\\\n",
    "            .where(col(\"sentiment\")==\"neutral\")\\\n",
    "            .drop(\"emojiTop\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-bahrain",
   "metadata": {},
   "source": [
    "#### positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "electoral-script",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------+------------+-------------+-----------+---------------+\n",
      "|emoji|sentiment|overallCount|    frequency|avCountPost|overallFreqDiff|\n",
      "+-----+---------+------------+-------------+-----------+---------------+\n",
      "|   🔻| positive|        4115|  9.323248E-4|  23.248587|       4114.999|\n",
      "|    ↙| positive|          21|1.05347435E-5|       10.5|      20.999989|\n",
      "|   🎀| positive|        3788| 0.0032552357|    6.12945|      3787.9968|\n",
      "|    ▫| positive|         158| 1.4748641E-4|   5.642857|      157.99985|\n",
      "|   🌺| positive|        5470| 0.0061575575|   4.679213|      5469.9937|\n",
      "+-----+---------+------------+-------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "resultEmoji_df\\\n",
    "            .withColumn(\"emojiTop\",row_number().over(windowSpec))\\\n",
    "            .where(col(\"emojiTop\") < 6)\\\n",
    "            .where(col(\"sentiment\")==\"positive\")\\\n",
    "            .drop(\"emojiTop\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "promising-wagon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text: string]"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folowers_posts_text.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-mount",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "### Find probable \"fans\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-blowing",
   "metadata": {},
   "source": [
    "#### First we create window to order data firstly by 'likerId' and secondly by 'likes_count'. Then we start working with data - firstly counting how many likes did liker put to posts of each 'ownerId'. Then we order collected data by \"likerId\", \"likes_count\" and apply window created in the begining, which allows us to create column with top of liked 'ownerId'. Then we save only columns with 'likersTop' < 11, since we need to get Top-10. Finally, we group by 'likerId', creating a column with lists of top-10 (or less) liked users for each liker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "registered-fence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|likerId|         topLikedIds|\n",
      "+-------+--------------------+\n",
      "|    496|          [59139083]|\n",
      "|   2142|   [5411213, 152962]|\n",
      "|   3918|         [145254284]|\n",
      "|   7880|           [2812004]|\n",
      "|   9376|            [111195]|\n",
      "|  12046|           [3824163]|\n",
      "|  13832|             [15221]|\n",
      "|  18944|             [15221]|\n",
      "|  20135|  [75791, 174291546]|\n",
      "|  20683|            [591512]|\n",
      "|  20924|            [327458]|\n",
      "|  23364|         [131719318]|\n",
      "|  26087|            [482756]|\n",
      "|  26623|            [216575]|\n",
      "|  28577|    [471165, 167177]|\n",
      "|  30654|             [55586]|\n",
      "|  32445|            [715211]|\n",
      "|  40515|[2070090, 27420, ...|\n",
      "|  41751|            [770885]|\n",
      "|  42468|              [1087]|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "windowSpec = Window.partitionBy(\"likerId\").orderBy(col(\"likes_count\").desc())\n",
    "\n",
    "followers_posts_likes_df\\\n",
    "                        .groupby(\"likerId\", \"ownerId\")\\\n",
    "                        .agg(F.count(\"ownerId\").name(\"likes_count\"))\\\n",
    "                        .orderBy(\"likerId\", \"likes_count\", ascending=False)\\\n",
    "                        .withColumn(\"likersTop\",row_number().over(windowSpec))\\\n",
    "                        .where(col(\"likersTop\") < 11)\\\n",
    "                        .groupby(\"likerId\")\\\n",
    "                        .agg(F.collect_list(col(\"ownerId\")).name(\"topLikedIds\"))\\\n",
    "                        .show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "confidential-windsor",
   "metadata": {},
   "outputs": [],
   "source": [
    "followers_posts_likes_df\\\n",
    "                        .groupby(\"likerId\", \"ownerId\")\\\n",
    "                        .agg(F.count(\"ownerId\").name(\"likes_count\"))\\\n",
    "                        .orderBy(\"likerId\", \"likes_count\", ascending=False)\\\n",
    "                        .withColumn(\"likersTop\",row_number().over(windowSpec))\\\n",
    "                        .where(col(\"likersTop\") < 11)\\\n",
    "                        .groupby(\"likerId\")\\\n",
    "                        .agg(F.collect_list(col(\"ownerId\")).name(\"topLikedIds\")).write.parquet(\"hdfs:///tmp/zpinaev-244202/lab2_results_5.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-expert",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "### Find probable friends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "computational-canberra",
   "metadata": {},
   "outputs": [],
   "source": [
    "likers = followers_posts_likes_df\\\n",
    "                        .where(col(\"likerId\") != col(\"ownerId\"))\\\n",
    "                        .groupby(\"likerId\", \"ownerId\")\\\n",
    "                        .agg(F.count(\"ownerId\").name(\"likes_count\"))\\\n",
    "                        .orderBy(\"likerId\", \"likes_count\", ascending=False)\\\n",
    "                        .withColumn(\"likersTop\",row_number().over(windowSpec))\\\n",
    "                        .where(col(\"likersTop\") < 2)\\\n",
    "                        .groupby(col(\"likerId\").name(\"likerId_1\"))\\\n",
    "                        .agg(F.collect_list(col(\"ownerId\"))[0].name(\"topLikedId_1\"))\n",
    "                        \n",
    "\n",
    "likers_2 = followers_posts_likes_df\\\n",
    "                        .where(col(\"likerId\") != col(\"ownerId\"))\\\n",
    "                        .groupby(\"likerId\", \"ownerId\")\\\n",
    "                        .agg(F.count(\"ownerId\").name(\"likes_count\"))\\\n",
    "                        .orderBy(\"likerId\", \"likes_count\", ascending=False)\\\n",
    "                        .withColumn(\"likersTop\",row_number().over(windowSpec))\\\n",
    "                        .where(col(\"likersTop\") < 2)\\\n",
    "                        .groupby(col(\"likerId\").name(\"likerId_2\"))\\\n",
    "                        .agg(F.collect_list(col(\"ownerId\"))[0].name(\"topLikedId_2\"))\n",
    "\n",
    "\n",
    "friends = likers.join(likers_2, \n",
    "                    on=[likers.topLikedId_1 == likers_2.likerId_2, likers.likerId_1 == likers_2.topLikedId_2],\n",
    "                    how = \"inner\")\\\n",
    "                .drop(\"topLikedId_1\", \"topLikedId_2\")\\\n",
    "                .select(col(\"likerId_1\").name(\"friend_1\"), \n",
    "                        col(\"likerId_2\").name(\"friend_2\")).cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-creek",
   "metadata": {},
   "source": [
    "#### Showing probable friends without \"self-likers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "graduate-albania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n",
      "| friend_1| friend_2|\n",
      "+---------+---------+\n",
      "|339234422|  1168939|\n",
      "|152590008| 95578891|\n",
      "|262884476|298700947|\n",
      "|253967472|387540163|\n",
      "|   394348| 50185099|\n",
      "|176461282|173161528|\n",
      "|145291328| 87779884|\n",
      "| 71427292| 70730078|\n",
      "| 99842535|245259928|\n",
      "| 95811304|291661975|\n",
      "|  3420917|   817770|\n",
      "| 77495114|  7555534|\n",
      "| 22829194|134347125|\n",
      "|214091560|233174236|\n",
      "|291309029|450562601|\n",
      "+---------+---------+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "friends.show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "id": "varying-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "friends.write.parquet(\"hdfs:///tmp/zpinaev-244202/lab2_results_6.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "id": "major-brother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[friend_1: int, friend_2: int]"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "friends.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-smoke",
   "metadata": {},
   "source": [
    "## Task 7\n",
    "### Bonus task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "hourly-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting threshold to zero\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "fleet-stake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10'"
      ]
     },
     "execution_count": 605,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get current Threshold\n",
    "spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "id": "demanding-header",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 607,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = spark.range(10000)\n",
    "df2 = spark.range(10000)\n",
    "\n",
    "df1.join(df2, on=[\"id\"]).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-sauce",
   "metadata": {},
   "source": [
    "<img src=\"Shuffle.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "peaceful-divide",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(5) Project [id#61449L]\n",
      "+- *(5) SortMergeJoin [id#61449L], [id#61451L], Inner\n",
      "   :- *(2) Sort [id#61449L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(id#61449L, 200), ENSURE_REQUIREMENTS, [id=#11836]\n",
      "   :     +- *(1) Range (0, 10000, step=1, splits=2)\n",
      "   +- *(4) Sort [id#61451L ASC NULLS FIRST], false, 0\n",
      "      +- ReusedExchange [id#61451L], Exchange hashpartitioning(id#61449L, 200), ENSURE_REQUIREMENTS, [id=#11836]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setting threshold to zero\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", 0)\n",
    "\n",
    "# making join and see, that we have here SortMergeJoin and Exchanges\n",
    "# which means - we have our data shuffled during join\n",
    "df1.join(df2, on=[\"id\"]).explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "several-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we create bucketed table which will allow to avoid exchanging thus \n",
    "# avoiding shuffling\n",
    "\n",
    "df = spark.range(1, 16000, 1, 16).select(\n",
    "        F.col(\"id\").alias(\"key\"), F.rand(12).alias(\"value\")\n",
    "    )\n",
    "\n",
    "df.write.bucketBy(16, \"key\").sortBy(\"value\").saveAsTable(\n",
    "    \"bucketed\", format=\"parquet\", mode=\"overwrite\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "bearing-ancient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Project [key#61490L, value#61491, value#61497]\n",
      "+- *(3) SortMergeJoin [key#61490L], [key#61496L], Inner\n",
      "   :- *(1) Sort [key#61490L ASC NULLS FIRST], false, 0\n",
      "   :  +- *(1) Filter isnotnull(key#61490L)\n",
      "   :     +- *(1) ColumnarToRow\n",
      "   :        +- FileScan parquet default.bucketed[key#61490L,value#61491] Batched: true, DataFilters: [isnotnull(key#61490L)], Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/nfs-home/spark-warehouse/bucketed], PartitionFilters: [], PushedFilters: [IsNotNull(key)], ReadSchema: struct<key:bigint,value:double>, SelectedBucketsCount: 16 out of 16\n",
      "   +- *(2) Sort [key#61496L ASC NULLS FIRST], false, 0\n",
      "      +- *(2) Filter isnotnull(key#61496L)\n",
      "         +- *(2) ColumnarToRow\n",
      "            +- FileScan parquet default.bucketed[key#61496L,value#61497] Batched: true, DataFilters: [isnotnull(key#61496L)], Format: Parquet, Location: InMemoryFileIndex[file:/home/jovyan/nfs-home/spark-warehouse/bucketed], PartitionFilters: [], PushedFilters: [IsNotNull(key)], ReadSchema: struct<key:bigint,value:double>, SelectedBucketsCount: 16 out of 16\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# now we join two bucketed tables\n",
    "\n",
    "t1 = spark.table('bucketed')\n",
    "t2 = spark.table('bucketed')\n",
    "\n",
    "# so here we see no exchanges, meaning there is no shuffling now and also\n",
    "# no SortMergeJoin\n",
    "t2.join(t1, 'key').explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "familiar-merit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 613,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.join(t1, 'key').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-toddler",
   "metadata": {},
   "source": [
    "#### Here on computational dag we see only exchange connected with count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-shield",
   "metadata": {},
   "source": [
    "<img src=\"No_Shuffle.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "banner-journey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[itemType: string, ownerId: int, itemId: int, likerId: int]"
      ]
     },
     "execution_count": 647,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.unpersist()\n",
    "posts_likes_df.unpersist()\n",
    "followers_df.unpersist()\n",
    "followers_posts_df.unpersist()\n",
    "followers_posts_likes_df.unpersist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
